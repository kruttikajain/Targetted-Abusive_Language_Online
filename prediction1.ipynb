{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "prediction1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kruttikajain/Targetted-Abusive_Language_Online/blob/master/prediction1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "01f361ddc47e0b386595316fe3d7f4dabbd260db",
        "id": "XE0VGEF8ZA6M",
        "colab_type": "text"
      },
      "source": [
        "# Abusive Language Online \n",
        "\n",
        "Predition1: predict OFF/NOT\n",
        "\n",
        "* Upload it each time: Dataset: [data](http://demo.clab.cs.cmu.edu/ethical_nlp2019/homeworks/hw3/hw3.html)\n",
        "\n",
        "\n",
        "1.   train.tsv\n",
        "2.   dev.tsv\n",
        "3.   test.tsv\n",
        "\n",
        "* Need manually add log.txt\n",
        "* Mount drive to load GloVe embeddings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqazyGPwaTEe",
        "colab_type": "text"
      },
      "source": [
        "# Import useful lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "ONg01KM4ZA6N",
        "colab_type": "code",
        "outputId": "d16fd91c-8bf1-49f2-8fb9-4e7998dfece9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from logging import handlers\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import random \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, CuDNNLSTM, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhWzw5Rtajm7",
        "colab_type": "text"
      },
      "source": [
        "# Prepare logging file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vggd1S4jZA6R",
        "colab_type": "code",
        "outputId": "c2cc657b-4004-4214-bbb7-2d4008cca0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "def init_logger(log_file):\n",
        "    if not os.path.exists(log_file):\n",
        "        os.makedirs(os.path.dirname(log_file))\n",
        "\n",
        "    log = logging.getLogger('')\n",
        "    log.setLevel(logging.INFO)\n",
        "    output_format = logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "    std_out_handler = logging.StreamHandler(sys.stdout)\n",
        "    std_out_handler.setFormatter(output_format)\n",
        "    logging.getLogger().addHandler(std_out_handler)\n",
        "    file_handler = logging.handlers.RotatingFileHandler(log_file, maxBytes=(1048576*5), backupCount=7)\n",
        "    file_handler.setFormatter(output_format)\n",
        "    logging.getLogger().addHandler(file_handler)\n",
        "\n",
        "init_logger('./log.txt')\n",
        "logging.info('=============start=================')\n",
        "logging.info('logging file prepared')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1865954b82e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0minit_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./log.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=============start================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logging file prepared'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1865954b82e4>\u001b[0m in \u001b[0;36minit_logger\u001b[0;34m(log_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '.'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11l-8APTaOVP",
        "colab_type": "text"
      },
      "source": [
        "# Data proprecessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaD_vgEytb9u",
        "colab_type": "text"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flhVY6tUu-wN",
        "colab_type": "code",
        "outputId": "6d094e81-c932-452f-b4db-ec55cd3668aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SokHSWetCXCo",
        "colab_type": "code",
        "outputId": "679b3038-e697-4c96-dfc2-b3147e871bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%cd gdrive/My\\ Drive/Abusive_language_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/Abusive_language_data'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhfBBtlIHN6p",
        "colab_type": "code",
        "outputId": "b5d24566-4ce4-42c7-ce25-d9b96cb21929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = 'My Drive/246_Project' \n",
        "# replace with your Github username \n",
        "GIT_USERNAME = \"kruttikajain\" \n",
        "# definitely replace with your\n",
        "GIT_TOKEN = \"5fae1c9f18e3a0c680bf35e9ef63c72308ef2b4c\"  \n",
        "# Replace with your github repository in this case we want \n",
        "# to clone deep-learning-v2-pytorch repository\n",
        "GIT_REPOSITORY = \"Targetted-Abusive_Language_Online\" \n",
        "\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# It's good to print out the value if you are not sure \n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "# In case we haven't created the folder already; we will create a folder in the project path \n",
        "!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a8d72646e184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mGIT_REPOSITORY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Targetted-Abusive_Language_Online\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mPROJECT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMY_GOOGLE_DRIVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# It's good to print out the value if you are not sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ROOT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOtNdORiaKqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    logging.info('loading the dataset...')\n",
        "    train_df = pd.read_csv(\"./train.tsv\", sep=\"\\t\")\n",
        "    val_df = pd.read_csv(\"./dev.tsv\", sep=\"\\t\")\n",
        "    test_df = pd.read_csv(\"./test.tsv\", sep=\"\\t\")\n",
        "    \n",
        "    # shape of df, column names\n",
        "    logging.info('Train shape : ' + str(train_df.shape)) # 'text', 'label', 'category'\n",
        "    logging.info('Val shape: ' + str(val_df.shape))\n",
        "    logging.info('Test shape: ' + str(test_df.shape))\n",
        "    \n",
        "    logging.info('train_df.columns: ' + train_df.columns)\n",
        "    logging.info('val_df.columns: ' + val_df.columns)\n",
        "    logging.info('test_df.columns: ' + test_df.columns)\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO55Z3UaXUsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApWoZxt1dc-a",
        "colab_type": "text"
      },
      "source": [
        "**Attributes in data:**\n",
        "\n",
        "\n",
        "***Trainning data:***  (10592, 3) \\\\\n",
        "\n",
        "* **text:** \\\\\n",
        "tweet content\n",
        "\n",
        "* **label:** \\\\\n",
        "1.   (NOT) Not Offensive - This post does not contain offense or profanity\n",
        "2.   (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense\n",
        "\n",
        "* **category:** (if label is 'OFF') \\\\\n",
        "1.   (TIN) Targeted Insult and Threats - A post containing an insult or threat to an individual, a group, or others\n",
        "2.   (UNT) Untargeted - A post containing non-targeted profanity and swearing.\n",
        "\n",
        "***Validation data:***  (1324, 3) \\\\\n",
        "\n",
        "***Testing data***:  'text' (1324, 1) \\\\\n",
        "* **text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEJfFD-hkhu5",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g52M8qtkk36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_cleaning(train_df, val_df, test_df):\n",
        "    # shuffle data\n",
        "    train_df = train_df.sample(frac=1, random_state=2020).reset_index(drop=True)\n",
        "    \n",
        "    # lo lowercae\n",
        "    train_df['text'] = train_df['text'].str.lower()\n",
        "    val_df['text'] = val_df['text'].str.lower()\n",
        "    test_df['text'] = test_df['text'].str.lower()\n",
        "\n",
        "    # delete \"noise words\"\n",
        "    noise = [\"url\",\"user\",\"@\",\"&amp;\",\"#\",\"-\",'.',\"!\",\"?\",\"rt\",\"dm\",\"retweet\",\"rt\",\"dm\"]\n",
        "    for WORD in noise:\n",
        "        train_df['text'] = train_df['text'].str.replace(WORD, '')\n",
        "        val_df['text'] = val_df['text'].str.replace(WORD, '')\n",
        "        test_df['text'] = test_df['text'].str.replace(WORD, '')\n",
        "\n",
        "    # change label to 0/a\n",
        "    train_df['label'] = train_df['label'].map({'OFF': 1, 'NOT': 0})\n",
        "    val_df['label'] = val_df['label'].map({'OFF': 1, 'NOT': 0})\n",
        "\n",
        "    # one-hot encoding of category\n",
        "    train_df = pd.concat([train_df,pd.get_dummies(train_df['category'], prefix='category')],axis=1)\n",
        "    train_df.drop(['category'],axis=1, inplace=True)\n",
        "    \n",
        "    val_df = pd.concat([val_df,pd.get_dummies(val_df['category'], prefix='category')],axis=1)\n",
        "    val_df.drop(['category'],axis=1, inplace=True)\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = data_cleaning(train_df, val_df, test_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muL8B6aXSu3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBBjRW0-Ubf",
        "colab_type": "text"
      },
      "source": [
        "Check the content of abusive text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6em0dtx8D3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abusive_df = train_df.loc[train_df['label'] == 1]\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "abusive_df['text'].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plq9OgoGtqb8",
        "colab_type": "text"
      },
      "source": [
        "## Data distribution and visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKV_v3kvlmg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count how many letters in a sentence\n",
        "def label_distribution(train_df):\n",
        "    #  length of text\n",
        "    count = train_df['text'].str.split().apply(len).value_counts()\n",
        "    count.sort_index(inplace=True)\n",
        "    count.index = count.index.astype(str) + ' words:'\n",
        "    # logging.info(count[0:5])\n",
        "    # logging.info(count[-5:])\n",
        "    plt.plot(range(len(count)), count, color='blue')\n",
        "    plt.title(\"Text length\")\n",
        "    plt.show()\n",
        "    # label distribution\n",
        "    logging.info('number of label = 1 : ' + str((train_df['label'] != 0).sum()))\n",
        "    logging.info('number of category_TIN = 1: ' + str((train_df['category_TIN'] != 0).sum()))\n",
        "    logging.info('number of category_UNT = 1: ' + str((train_df['category_UNT'] != 0).sum()))\n",
        "\n",
        "    # plot histogram\n",
        "    train_df['label'].plot.hist(bins=2, title='label distribution')\n",
        "    plt.show()\n",
        "\n",
        "label_distribution(train_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwxnd29E0lLP",
        "colab_type": "text"
      },
      "source": [
        "**Property of dataset**\n",
        "\n",
        "*   **Length of text:** [2, 60]\n",
        "\n",
        "*   **label:** \n",
        "1.   label = 0: 7072\n",
        "2.   label = 1: 3520\n",
        "\n",
        "* Among label = 1: \\\\\n",
        "1.   category_TIN = 1: 3089\n",
        "2.   category_UNT = 1: 431\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VD0DcUi-mGZ",
        "colab_type": "text"
      },
      "source": [
        "Word cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouIzGaJMZA6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word cloud\n",
        "normal_df = train_df.loc[train_df.label == 0]\n",
        "abusive_df = train_df.loc[train_df.label == 1]\n",
        "\n",
        "normal_text_array = np.array(normal_df['text'])\n",
        "abusive_text_array = np.array(abusive_df['text'])\n",
        "\n",
        "normal_text = ''.join(normal_text_array)\n",
        "abusive_text = ''.join(abusive_text_array)\n",
        "\n",
        "logging.info(\"convert to text finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfupiI1PZA6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(normal_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# abusive\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(abusive_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6rcUOlh_IOy",
        "colab_type": "text"
      },
      "source": [
        "Delete some common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In65Isr_Am-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal_text = normal_text.replace('liberal','',1000).replace('people','',1000).replace('will','',1000)\n",
        "abusive_text = abusive_text.replace('liberal','',1000).replace('people','',1000).replace('will','',1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GXy9WegBJwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(normal_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# abusive\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(abusive_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kCi_RoLE8wP",
        "colab_type": "text"
      },
      "source": [
        "# Split data to X and y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8D_XrHPEaIV",
        "colab_type": "text"
      },
      "source": [
        "Split data to X and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcgmnATZA6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_val(train_df, val_df, test_df):\n",
        "    logging.info('splitting X and y ...')\n",
        "    train_X = train_df[\"text\"].fillna(\"_na_\").values\n",
        "    val_X = val_df[\"text\"].fillna(\"_na_\").values\n",
        "    test_X = test_df[\"text\"].fillna(\"_na_\").values\n",
        "\n",
        "    train_y = train_df['label'].values\n",
        "    val_y = val_df['label'].values\n",
        "\n",
        "    logging.info('finished splitting X and y')\n",
        "    return train_X, val_X, test_X, train_y, val_y\n",
        "\n",
        "train_X, val_X, test_X, train_y, val_y = split_train_val(train_df, val_df, test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdk4s-pCZA6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_X.shape, train_y.shape)\n",
        "print(val_X.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feMxvs73D-gx",
        "colab_type": "text"
      },
      "source": [
        "Tokenize and padding each sentence, split datafram to attributes and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNGTN3kVZA6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# each word embedding to 300 dimension\n",
        "embed_size = 300\n",
        "# count of vocabulary words\n",
        "max_features = 50000\n",
        "# length of each sentences\n",
        "max_len = 70\n",
        "\n",
        "def token_sentence(train_X, val_X, test_X ):\n",
        "    logging.info('tokenizing sentence...')\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    tokenizer.fit_on_texts(list(train_X))\n",
        "    train_X = tokenizer.texts_to_sequences(train_X)\n",
        "    val_X = tokenizer.texts_to_sequences(val_X)\n",
        "    test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "    logging.info('padding sentence...')\n",
        "    train_X = pad_sequences(train_X, maxlen=max_len)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len)\n",
        "    test_X = pad_sequences(test_X, maxlen=max_len)\n",
        "\n",
        "    logging.info('all finished...')\n",
        "    return train_X, val_X, test_X, tokenizer\n",
        "\n",
        "train_X, val_X, test_X, tokenizer = token_sentence(train_X, val_X, test_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBUErOp_QEK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AenyxjOSMCDL",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL2IvlW8qLJQ",
        "colab_type": "text"
      },
      "source": [
        "## Model1: base line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L5EZKeUQgtj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-uZ5egkQd58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYDgYFtKqO40",
        "colab_type": "text"
      },
      "source": [
        "### Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odb9nd5WQST8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dt_model(train_X, train_y, val_X, cal_y):\n",
        "    dt_clf = tree.DecisionTreeClassifier()\n",
        "    dt_clf = dt_clf.fit(train_X, train_y)\n",
        "    pred_val_y = dt_clf.predict(val_X).reshape(-1,1)\n",
        "    dt_acc = accuracy_score(pred_val_y, val_y)\n",
        "    dt_f1_score = f1_score(pred_val_y, val_y)\n",
        "    return dt_acc, dt_f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NbcgKG1RcQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt_acc, dt_f1_score = dt_model(train_X, train_y, val_X, val_y)\n",
        "print('dt_acc: ', dt_acc, ', dt_f1_score: ',  dt_f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63QJAP9RqSle",
        "colab_type": "text"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-FpKqDpWoiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_model(train_X, train_y, val_X, cal_y):\n",
        "    lr_clf = LogisticRegression(random_state=0, max_iter=4000).fit(train_X, train_y)\n",
        "    pred_val_y = lr_clf.predict(val_X).reshape(-1,1)\n",
        "    lr_acc = accuracy_score(pred_val_y, val_y)\n",
        "    lr_f1_score = f1_score(pred_val_y, val_y)\n",
        "    return lr_acc, lr_f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8B44OR0W_vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_acc, lr_f1_score = lr_model(train_X, train_y, val_X, val_y)\n",
        "print('lr_acc: ', lr_acc, ', lr_f1_score: ',  lr_f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i7BpltoqZza",
        "colab_type": "text"
      },
      "source": [
        "### GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RDWko-oXO9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gNB_model(train_X, train_y, val_X, cal_y):\n",
        "    gNB_clf = GaussianNB()\n",
        "    gNB_clf = gNB_clf.fit(train_X, train_y)\n",
        "    pred_val_y = gNB_clf.predict(val_X).reshape(-1,1)\n",
        "    gNB_acc = accuracy_score(pred_val_y, val_y)\n",
        "    gNB_f1_score = f1_score(pred_val_y, val_y)\n",
        "    return gNB_acc, gNB_f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heu4JLHgX164",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gNB_acc, gNB_f1_score = gNB_model(train_X, train_y, val_X, val_y)\n",
        "print('gNB_acc: ', gNB_acc, ', gNB_f1_score: ',  gNB_f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REnqEUw_kKI8",
        "colab_type": "text"
      },
      "source": [
        "## Model2 : LSTM + Without Pretrained Embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9wKqZveyapX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Add an Embedding layer expecting input vocab of size 50000, and\n",
        "# output embedding dimension of size 300.\n",
        "model.add(layers.Embedding(input_dim=50000, output_dim=300))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(10,activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71VTQNZjzgn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "callbacks = EarlyStopping(monitor='val_loss', min_delta=0, patience = 2)\n",
        "history = model.fit(train_X, \n",
        "                    train_y, \n",
        "                    batch_size=512, \n",
        "                    epochs=14, \n",
        "                    validation_data=(val_X, val_y),\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v_WWWREdP_w",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiaEcGWWZA6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot history\n",
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "47b63dca0247a08a808db7ae6eea33065c554948",
        "id": "M4y418b5ZA6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation the model(f1-score)\n",
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "print(pred_noemb_val_y)\n",
        "threshes=[]\n",
        "f1_scores=[]\n",
        "accuracy_scores=[]\n",
        "for thresh in np.arange(0.1, 0.801, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    threshes.append(thresh)\n",
        "    logging.info(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    f1_scores.append(metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int)))\n",
        "    print(\"Accuracy at threshold {0} is {1}\".format(thresh, metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    accuracy_scores.append(metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC0KxHrGnewO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot two measures\n",
        "plt.plot(threshes, f1_scores, color='blue', label='f1')\n",
        "plt.plot(threshes, accuracy_scores, color='orange', label='acc')\n",
        "plt.title('f1_scores/acc')\n",
        "plt.ylabel('f1_scores/acc')\n",
        "plt.xlabel('threshold')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJSYLb3ykxyT",
        "colab_type": "text"
      },
      "source": [
        "## Model3: LSTM + Pretrained embeddings\n",
        "\n",
        "Different Embeddings:\n",
        "\n",
        "GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
        "paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
        "\n",
        "wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS3iwFGqwHvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "embeddings_index = {}\n",
        "logging.info(\"Loading Glove Model\")\n",
        "with io.open('drive/My Drive/Colab Notebooks/246Project/glove.840B.300d.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = ''.join(values[:-300])\n",
        "        coefs = np.asarray(values[-300:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "logging.info(\"Loading Glove Model Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7fswnbHDI2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "print(all_embs.shape, emb_mean, emb_std, embed_size )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOx2DkzgDS-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "len(word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Ng8SHSDxBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_words = min(max_features, 1 + len(word_index))\n",
        "nb_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWf0qQ2iD2ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNslPaHb193k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word, i in word_index.items(): \n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RWtEloU2M1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.initializers import Constant\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Embedding(nb_words,\n",
        "                            300,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len,\n",
        "                            trainable=False))\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(10,activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txx27Bzd3gLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeVa4_2m3kzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "callbacks = EarlyStopping(monitor='val_loss', min_delta=0, patience = 2)\n",
        "\n",
        "history = model.fit(train_X, \n",
        "                    train_y, \n",
        "                    batch_size=512, \n",
        "                    epochs=15, \n",
        "                    validation_data=(val_X, val_y),\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JjJbtUNn3cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AslhlttleNnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation the model(f1-score)\n",
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "print(pred_noemb_val_y)\n",
        "threshes=[]\n",
        "f1_scores=[]\n",
        "accuracy_scores=[]\n",
        "for thresh in np.arange(0.1, 0.801, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    threshes.append(thresh)\n",
        "    logging.info(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    f1_scores.append(metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int)))\n",
        "    print(\"Accuracy at threshold {0} is {1}\".format(thresh, metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    accuracy_scores.append(metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaSwqigUZA60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot two measures\n",
        "plt.plot(threshes, f1_scores, color='blue', label='f1')\n",
        "plt.plot(threshes, accuracy_scores, color='orange', label='acc')\n",
        "plt.title('f1_scores/acc')\n",
        "plt.ylabel('f1_scores/acc')\n",
        "plt.xlabel('threshold')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "383e51177bf33da0b8fee42dd6a093908b808f64",
        "id": "nGYvEk8EZA6z",
        "colab_type": "text"
      },
      "source": [
        "## Model4: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOh74l0KZA65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.info('=========done===========')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX0YxXa_dUJz",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gT0baX2dXqc",
        "colab_type": "text"
      },
      "source": [
        "# Prediction 2\n"
      ]
    }
  ]
}